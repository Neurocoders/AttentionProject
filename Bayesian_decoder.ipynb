{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bayesian_decoder.ipynb","provenance":[{"file_id":"1b0ra-XC4ntGaT-eZHlZIenZKnugBsbT_","timestamp":1595917767544}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/Neurocoders/AttentionProject/blob/branch2/load_steinmetz_data_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"bEqdz1ZUMaj1","colab_type":"text"},"source":["## Loading of Steinmetz data\n","\n","includes some visualizations"]},{"cell_type":"code","metadata":{"id":"TLWjKq8bLDqm","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Data retrieval\n","import os, requests\n","\n","fname = []\n","for j in range(3):\n","  fname.append('steinmetz_part%d.npz'%j)\n","url = [\"https://osf.io/agvxh/download\"]\n","url.append(\"https://osf.io/uv3mw/download\")\n","url.append(\"https://osf.io/ehmw2/download\")\n","\n","fname.append('steinmetz_st.npz')\n","fname.append('steinmetz_wav.npz')\n","fname.append('steinmetz_lfp.npz')\n","\n","\n","url.append(\"https://osf.io/4bjns/download\")\n","url.append(\"https://osf.io/ugm9v/download\")\n","url.append(\"https://osf.io/kx3v9/download\")\n","\n","for j in range(len(url)):\n","  if not os.path.isfile(fname[j]):\n","    try:\n","      r = requests.get(url[j])\n","    except requests.ConnectionError:\n","      print(\"!!! Failed to download data !!!\")\n","    else:\n","      if r.status_code != requests.codes.ok:\n","        print(\"!!! Failed to download data !!!\")\n","      else:\n","        with open(fname[j], \"wb\") as fid:\n","          fid.write(r.content)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2kYuM36BERNX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1596034692512,"user_tz":-330,"elapsed":34838,"user":{"displayName":"Keerthana Manikandan","photoUrl":"https://lh6.googleusercontent.com/-QQCmEevJOBM/AAAAAAAAAAI/AAAAAAAAAMI/-iZbsmOHbZk/s64/photo.jpg","userId":"01482527171893239923"}},"outputId":"57ff040a-6805-4eec-edfd-caafdb85dc1c"},"source":["import numpy as np\n","\n","alldat = np.array([])\n","for j in range(3):\n","  alldat = np.hstack((alldat, np.load('steinmetz_part%d.npz'%j, allow_pickle=True)['dat']))\n","\n","# select just one of the recordings here. 11 is nice because it has some neurons in vis ctx. \n","dat = alldat[11]\n","\n","dat_LFP = np.load('steinmetz_lfp.npz', allow_pickle=True)['dat']\n","dat_LFP = dat_LFP[11] #beware of lfp vs LFP here\n","print(dat_LFP.keys())\n","dat_WAV = np.load('steinmetz_wav.npz', allow_pickle=True)['dat']\n","dat_WAV = dat_WAV[11]\n","print(dat_WAV.keys())\n","\n","print(dat.keys())\n","\n","# select just one of the recordings here. 11 is nice because it has some neurons in vis ctx. \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['lfp', 'lfp_passive', 'brain_area_lfp'])\n","dict_keys(['waveform_w', 'waveform_u', 'trough_to_peak'])\n","dict_keys(['spks', 'wheel', 'pupil', 'response', 'response_time', 'bin_size', 'stim_onset', 'contrast_right', 'contrast_left', 'brain_area', 'feedback_time', 'feedback_type', 'gocue', 'mouse_name', 'date_exp', 'trough_to_peak', 'active_trials', 'contrast_left_passive', 'contrast_right_passive', 'spks_passive', 'pupil_passive', 'wheel_passive', 'prev_reward', 'ccf', 'ccf_axes', 'cellid_orig', 'reaction_time', 'face', 'face_passive', 'licks', 'licks_passive'])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5K7UT7dyj_6R","colab_type":"text"},"source":["`alldat` contains 39 sessions from 10 mice, data from Steinmetz et al, 2019. Time bins for all measurements are 10ms, starting 500ms before stimulus onset. The mouse had to determine which side has the highest contrast. For each `dat = alldat[k]`, you have the following fields:\n","\n","* `dat['mouse_name']`: mouse name\n","* `dat['date_exp']`: when a session was performed\n","* `dat['spks']`: neurons by trials by time bins.    \n","* `dat['brain_area']`: brain area for each neuron recorded. \n","* `dat['contrast_right']`: contrast level for the right stimulus, which is always contralateral to the recorded brain areas.\n","* `dat['contrast_left']`: contrast level for left stimulus. \n","* `dat['gocue']`: when the go cue sound was played. \n","* `dat['response_times']`: when the response was registered, which has to be after the go cue. The mouse can turn the wheel before the go cue (and nearly always does!), but the stimulus on the screen won't move before the go cue.  \n","* `dat['response']`: which side the response was (`-1`, `0`, `1`). When the right-side stimulus had higher contrast, the correct choice was `-1`. `0` is a no go response. \n","* `dat['feedback_time']`: when feedback was provided. \n","* `dat['feedback_type']`: if the feedback was positive (`+1`, reward) or negative (`-1`, white noise burst).  \n","* `dat['wheel']`: exact position of the wheel that the mice uses to make a response, binned at `10ms`. \n","* `dat['pupil']`: pupil area  (noisy, because pupil is very small) + pupil horizontal and vertical position. \n","* `dat['lfp']`: recording of the local field potential in each brain area from this experiment, binned at `10ms`.\n","* `dat['brain_area_lfp']`: brain area names for the LFP channels. \n","* `dat['trough_to_peak']`: measures the width of the action potential waveform for each neuron. Widths `<=10` samples are \"putative fast spiking neurons\". \n","* `dat['waveform_w']`: temporal components of spike waveforms. `w@u` reconstructs the time by channels action potential shape. \n","* `dat['waveform_u]`: spatial components of spike waveforms.\n","* `dat['%X%_passive']`: same as above for `X` = {`spks`, `lfp`, `pupil`, `wheel`, `contrast_left`, `contrast_right`} but for  passive trials at the end of the recording when the mouse was no longer engaged and stopped making responses. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"raBVOEWgUK_B","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Import matplotlib and set defaults\n","from matplotlib import rcParams \n","from matplotlib import pyplot as plt\n","rcParams['figure.figsize'] = [20, 4]\n","rcParams['font.size'] =15\n","rcParams['axes.spines.top'] = False\n","rcParams['axes.spines.right'] = False\n","rcParams['figure.autolayout'] = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rOHgfqU5EX0m","colab_type":"code","cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":585},"executionInfo":{"status":"ok","timestamp":1596034693717,"user_tz":-330,"elapsed":1170,"user":{"displayName":"Keerthana Manikandan","photoUrl":"https://lh6.googleusercontent.com/-QQCmEevJOBM/AAAAAAAAAAI/AAAAAAAAAMI/-iZbsmOHbZk/s64/photo.jpg","userId":"01482527171893239923"}},"outputId":"da012105-9663-460c-f9ad-8454e1c72826"},"source":["#@title Run this cell if you want to see the shape of different data dictionary fields\n","\n","for keys in dat_LFP:\n","    try:\n","        print(f\"the shape of {keys} is:\", dat_LFP[keys].shape)\n","    except:\n","        print(f\"{keys}:\", dat_LFP[keys])\n","        \n","for keys in dat: # see the shape of contents of \"dat\" variable\n","    try:\n","        print(f\"the shape of {keys} is:\", dat[keys].shape)\n","    except:\n","        print(f\"{keys}:\", dat[keys])\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["the shape of lfp is: (12, 340, 250)\n","the shape of lfp_passive is: (12, 110, 250)\n","brain_area_lfp: ['DG', 'LGd', 'SUB', 'VISp', 'ACA', 'MOs', 'PL', 'CA1', 'DG', 'LH', 'MD', 'VISam']\n","the shape of spks is: (698, 340, 250)\n","the shape of wheel is: (1, 340, 250)\n","the shape of pupil is: (3, 340, 250)\n","the shape of response is: (340,)\n","the shape of response_time is: (340, 1)\n","bin_size: 0.01\n","stim_onset: 0.5\n","the shape of contrast_right is: (340,)\n","the shape of contrast_left is: (340,)\n","the shape of brain_area is: (698,)\n","the shape of feedback_time is: (340, 1)\n","the shape of feedback_type is: (340,)\n","the shape of gocue is: (340, 1)\n","mouse_name: Lederberg\n","date_exp: 2017-12-05\n","the shape of trough_to_peak is: (698,)\n","the shape of active_trials is: (450,)\n","the shape of contrast_left_passive is: (110,)\n","the shape of contrast_right_passive is: (110,)\n","the shape of spks_passive is: (698, 110, 250)\n","the shape of pupil_passive is: (3, 110, 250)\n","the shape of wheel_passive is: (1, 110, 250)\n","the shape of prev_reward is: (340, 1)\n","the shape of ccf is: (698, 3)\n","ccf_axes: ['ap', 'dv', 'lr']\n","the shape of cellid_orig is: (1219,)\n","the shape of reaction_time is: (340, 2)\n","the shape of face is: (1, 340, 250)\n","the shape of face_passive is: (1, 110, 250)\n","the shape of licks is: (1, 340, 250)\n","the shape of licks_passive is: (1, 110, 250)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0-ZlQQY3EaZf","colab_type":"code","cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1596034694163,"user_tz":-330,"elapsed":1579,"user":{"displayName":"Keerthana Manikandan","photoUrl":"https://lh6.googleusercontent.com/-QQCmEevJOBM/AAAAAAAAAAI/AAAAAAAAAMI/-iZbsmOHbZk/s64/photo.jpg","userId":"01482527171893239923"}},"outputId":"46f0aecd-d6d3-4b1a-b153-5c895c6a6e27"},"source":["#@title Import required libraries\n","# please use the same conventions across the document\n","import pandas as pd\n","import seaborn as sns\n","import scipy.stats as stats\n","import scipy.signal as signal\n","import scipy.fftpack as fftpack  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MwT9Qa-raqkS","colab_type":"code","colab":{}},"source":["#@title Data splitting\n","def split_stim_indices(dat):\n","  n_trials = len(dat['response'])\n","  no_stim = np.logical_and(dat['contrast_left'] == 0, dat['contrast_right'] == 0)\n","  one_side_stim = np.logical_xor(dat['contrast_left'] == 0, dat['contrast_right'] == 0)\n","  two_side_stim = np.logical_and(dat['contrast_left'] > 0, dat['contrast_right'] > 0)\n","  return (no_stim, one_side_stim, two_side_stim)\n","\n","def split_accuracy_indices(dat):\n","  n_trials = len(dat['response'])\n","  correct = []\n","  incorrect = []\n","  for i in range(n_trials):\n","    if (dat['contrast_left'][i] > dat['contrast_right'][i] and dat['response'][i] == 1 ):\n","      correct.append( True )\n","      incorrect.append(False)\n","    elif (dat['contrast_left'][i] < dat['contrast_right'][i] and dat['response'][i] == -1 ):\n","      correct.append( True )\n","      incorrect.append(False)\n","    elif (dat['contrast_left'][i] == 0 and dat['contrast_right'][i] == 0 and dat['response'][i] == 0 ):\n","      correct.append( True )\n","      incorrect.append(False)\n","    else:\n","      incorrect.append( True )\n","      correct.append(False)\n","  return (correct, incorrect)\n","\n","no_stim, one_side_stim, two_side_stim = split_stim_indices(dat)\n","correct, incorrect = split_accuracy_indices(dat)\n","#to get only one_side trials which are correct use np.logical_and(one_side_stim, correct)\n","correct_one_side = np.logical_and(one_side_stim, correct)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gjR7bhIIq5O4","colab_type":"code","colab":{}},"source":["eff_response = dat[\"response_time\"]-dat[\"gocue\"]\n","plotter = dat[\"response_time\"]\n","sns.distplot(plotter, hist=True, kde=True,  # plot histogram with kernel density\n","             bins=80, color = 'gray', \n","             hist_kws={'edgecolor':'black'},\n","             kde_kws={'linewidth': 4, 'color': 'k'});\n","sns.distplot(plotter[correct], hist=True, kde=True,  # plot histogram with kernel density\n","             bins=80, color = 'gray', \n","             hist_kws={'edgecolor':'black'},\n","             kde_kws={'linewidth': 4, 'color': 'r'});\n","sns.distplot(plotter[incorrect], hist=True, kde=True,  # plot histogram with kernel density\n","             bins=80, color = 'gray', \n","             hist_kws={'edgecolor':'black'},\n","             kde_kws={'linewidth': 4, 'color': 'g'});\n","sns.distplot(plotter[two_side_stim], hist=True, kde=True,  # plot histogram with kernel density\n","             bins=80, color = 'gray', \n","             hist_kws={'edgecolor':'black'},\n","             kde_kws={'linewidth': 4, 'color': 'b'});"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"noHwHQr1Eihm","colab_type":"text"},"source":["**Considerations:**\n","\n","1- go cue time, response time and feedback time are measured with respect to the same time reference point (have the same 0 time)\n","\n","2- cannot understand the \"reaction time\" variable\n","\n","3- have some infinity values in the reaction time! (confirm this?)"]},{"cell_type":"code","metadata":{"id":"hZuAwHJlEf4p","colab_type":"code","colab":{}},"source":["#------------ Initial required variables, gather them in here if possible--------------\n","\n","dt = 10 # binning at 10 ms\n","NT = dat_LFP['lfp'].shape[-1] # number of time bins\n","time_vec = dt * np.arange(NT)\n","total_trial = dat_LFP['lfp'].shape[1] # number of trials\n","\n","# lfp has form brain area* trial * time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1o44vtoo2QNG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":100},"executionInfo":{"status":"ok","timestamp":1596034778015,"user_tz":-330,"elapsed":12104,"user":{"displayName":"Keerthana Manikandan","photoUrl":"https://lh6.googleusercontent.com/-QQCmEevJOBM/AAAAAAAAAAI/AAAAAAAAAMI/-iZbsmOHbZk/s64/photo.jpg","userId":"01482527171893239923"}},"outputId":"9f5e122c-63df-4962-b84e-7b215f0df199"},"source":["def visualize_areas(data_LFP = dat_LFP,trial_num = 1,typ = \"hamming\", win_len = 6, \n","                 data_all = dat, fig_size = (18,10)):\n","    \"\"\"\n","    Returns two indices corresponding to the user defined brain regions to study LFP\n","  \n","    Args:\n","    data_LFP: dictionary of LFPs\n","    trial_num : Trial number to visualize\n","    typ:  type of filter window, choose from gaussian, hamming, and hann\n","    win_len: length of the filter window\n","    data_all: Contains the reaction times, go cue and other trail information \n","\n","    output:\n","    ind1: index of the first brain region that we want to study\n","    ind2: index of the second brain region that we want to study\n","    area1: name of the first brain region that we want to study\n","    area2: name of the second brain region that we want to study\n","\n","    \"\"\"\n","    print(data_LFP[\"brain_area_lfp\"])\n","    area1 = input(\"please insert the first lfp region to plot:\")\n","    area2 = input(\"please insert the second lfp region to plot:\")\n","    \n","    ind1 = data_LFP[\"brain_area_lfp\"].index(area1)\n","    ind2 = data_LFP[\"brain_area_lfp\"].index(area2)\n","    regions = np.array(dat_LFP[\"brain_area_lfp\"]) # this is for multiple occurences of one region\n","    \n","    # see if there are multiple recordings of one area\n","    if data_LFP[\"brain_area_lfp\"].count(area1) >1:\n","        what_area1 = int(input(\"more than region with this name was found,\\\n","        please specify which instance you want to see (1: first, 2:second,...)\"))\n","        ind1 = np.where(regions == area1)[0][what_area1-1]\n","\n","    if data_LFP[\"brain_area_lfp\"].count(area2) >1:\n","        what_area2 = int(input(\"more than region with this name was found,\\\n","        please specify which instance you want to see (1: first, 2:second,...)\"))\n","        ind2 = np.where(regions == area2)[0][what_area2-1]\n","\n","    # visualization of raw LFPs before filtering\n","    temp_inp = input(\"do you wish to visualize the 2 LFPs that you want to analyse? y/n\")\n","    if temp_inp == \"y\":\n","        plt.figure(figsize = (10,7))\n","        plt.plot(time_vec, data_LFP[\"lfp\"][ind1, trial_num,:], label = area1 );\n","        plt.plot(time_vec, data_LFP[\"lfp\"][ind2, trial_num, :], label = area2)\n","\n","        plt.axvline(x = (data_all[\"gocue\"])[trial_num] * 1000, color = 'black', label = \"go cue\") # need the go cue and response/reaction time \n","        plt.axvline(x = (data_all[\"response_time\"])[trial_num] * 1000,             # from the main data\n","                ls = '--', color = 'black', label = \"response time\")\n","\n","        plt.xlabel(\"time(ms)\", fontsize = 12)\n","        plt.ylabel(\"voltage\", fontsize = 12)\n","        plt.title(\"plot of two unfiltered LFPs\", fontsize = 13)\n","        plt.legend()\n","        plt.show()\n","\n","        # smoothing filtering\n","        # choosing the window type\n","    if typ == \"hann\":\n","        win = signal.windows.hann(win_len, sym=True)\n","    elif typ == \"gaussian\":\n","        st = float(input(\"you have chosen gaussian, please specify a number for gaussian filter's standard deviation\"))\n","        win = signal.windows.gaussian(win_len, st, sym=True)\n","    \n","    elif typ == \"hamming\":\n","        win = signal.windows.hamming(win_len, sym=True)\n","\n","    else:\n","        raise ValueError(\"type is not  hann, hamming, gaussian\")\n","\n","     # applying the filter using filtfilt    \n","    smooth_sign1 = signal.filtfilt(b = win, a = 1, x = data_LFP[\"lfp\"][ind1, trial_num, :], axis=- 1, padtype='odd', padlen=None, method='pad', irlen=None)\n","    smooth_sign2 = signal.filtfilt(b = win, a = 1, x = data_LFP[\"lfp\"][ind2, trial_num, :], axis=- 1, padtype='odd', padlen=None, method='pad', irlen=None)\n","\n","    # plotting filter results\n","    temp_inp2 = input(\"do you wish to visualize the results of your smoothing? y/n\")\n","    if temp_inp2 == 'y':\n","        fig, axs = plt.subplots(1,2,figsize = fig_size)\n","        \n","        axs[0].plot(time_vec, data_LFP[\"lfp\"][ind1, trial_num, :],label = 'Raw Signal')\n","        axs[0].plot(time_vec, smooth_sign1,label = 'Smoothened signal')\n","        axs[0].set(title = f\"LFP from {area1}\")\n","        \n","        #plt.figure(figsize = (10,7))\n","        axs[1].plot(time_vec,data_LFP[\"lfp\"][ind2, trial_num, :],label = 'Raw Signal')\n","        axs[1].plot(time_vec,smooth_sign2,label = 'Smoothened signal')\n","        axs[1].set(title = f\"LFP from {area2}\")\n","        plt.xlabel('Time'); plt.ylabel('Amplitude')\n","        plt.legend(); plt.show()\n","\n","    return smooth_sign1, smooth_sign2, area1, area2, ind1, ind2\n","\n","    \n","#@title Get Filtered LFP data for the interested brain areas\n","smooth_sig1, smooth_sig2, area1, area2, ind1, ind2 = visualize_areas(data_LFP = dat_LFP,trial_num = 1,typ = \"hann\", win_len = 4, \n","                                                         data_all = dat, fig_size = (18,10))\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["['DG', 'LGd', 'SUB', 'VISp', 'ACA', 'MOs', 'PL', 'CA1', 'DG', 'LH', 'MD', 'VISam']\n","please insert the first lfp region to plot:VISam\n","please insert the second lfp region to plot:LGd\n","do you wish to visualize the 2 LFPs that you want to analyse? y/nn\n","do you wish to visualize the results of your smoothing? y/nn\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B2pZBWA28kYr","colab_type":"code","colab":{}},"source":["#@ ---------------Fourier Transform--------------------\n","# NT => number of time points, NT/2 would be the nyquest \n","# dt => time bin size\n","dt = 10\n","# time_vec => time vector in ms\n","NT = dat_LFP['lfp'].shape[-1] # number of time bins\n","time_vec = dt * np.arange(NT)\n","\n","def fourier(NT = NT, dt = dt, signal1 = smooth_sig1, signal2 =  smooth_sig2,\n","            dat = dat_LFP,trial_num = 1, area1 = area1,\n","                area2 = area2, fig_size = (18,10)):\n","    \"\"\"\n","   \n","\n","    This function performs fourier transformation using FFT on the lfp signal and also\n","    plots the time series and frequency result of fourier. dat[region, trial_num, :]\n","    \n","    Inputs:\n","    NT: number of total time points\n","    dt: size of time bin\n","    signal1: first time seri to decompose, set to the first output of the smoothing by default\n","    signal2: second time seri to decompose, set to the second output of the smoothing by default\n","    dat: dictionary containing the lfp data\n","    trial_num: number of trial to plut, \n","    \n","\n","    Returns:\n","    hz, amp1, amp2\n","    hz: frequency vector (hz = np.linspace(0,sampl_rate, NT) )\n","    amp1: amplitude result of fourier transform of area 1 LFP\n","    amp2: amplitude result of fourier transform of area 1 LFP\n","    * both only contain elements up to the nyquist frequency \n","    \"\"\"\n","\n","    sampl_rate = 1/(dt/1000) # sampling rate\n","    nyquist = sampl_rate/2\n","\n","\n","    freq_seri1 = fftpack.fft(signal1) #compute freq seri\n","    freq_seri2 = fftpack.fft(signal2)\n","\n","    hz = np.linspace(0,sampl_rate, NT) # frequency vector same for all\n","   \n","    amp1 = 2.0/NT * np.abs(freq_seri1)  # amplitude vector,\n","    # 2 * is to add the amplitude from  negative frequencies to positive ones\n","    # divide by number of time points for normalization\n","    amp2 = 2.0/NT * np.abs(freq_seri2)\n","    \n","    \n","    # plot timeseries\n","    # temp_inp = input(\"do you want to visualize the results of your decomposition? y/n\")\n","\n","    # if temp_inp == 'y':\n","    #     fig, axs = plt.subplots(1,2, figsize = fig_size)\n","\n","    #     axs[0].plot(hz, amp1) # this will have both neg and pos freqs so we have to limit it to nyquist\n","    #     axs[0].set(ylabel='Amplitude',xlabel='Frequency (Hz)',title= f'FFT result from {area1}', xlim = [0, nyquist])  \n","    #     axs[1].plot(hz, amp2) # this will have both neg and pos freqs so we have to limit it to nyquist\n","    #     axs[1].set(ylabel='Amplitude',xlabel='Frequency (Hz)',title= f'FFT result from {area2}', xlim = [0, nyquist])\n","        \n","    #     plt.show()\n","\n","    # now we want to only return the elements of hz and amp that \n","    # up to the nyquist: this is to find the index of nearest element of hz to nyquist   \n","    return_ind = int(np.where(abs(hz-nyquist) == np.min(abs(hz - nyquist)))[0][0])+1\n","    # pdb.set_trace()\n","\n","    return hz[:return_ind], amp1[:return_ind], amp2[:return_ind]\n","\n","freq_vals,fft_signal1,fft_signal2 = fourier()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6v0sEURNLpUd","colab_type":"code","colab":{}},"source":["b = np.array([])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mCt9veHO7ny_","colab_type":"code","colab":{}},"source":["# print(freq_vals)\n","# len(dat['response'])\n","correct_trials    = np.where(correct_one_side == True)[0]\n","incorrect_trials  = np.where(correct_one_side == False)[0]\n","alpha_indices = np.where(np.logical_and(freq_vals>=8, freq_vals<=12)) # alpha - 8-12 Hz # get indices where frequency values are in alpha and theta range\n","theta_indices = np.where(np.logical_and(freq_vals>=4, freq_vals<=7))\n","a = np.mean(fft_signal1[alpha_indices])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"btFUnzKmJazN","colab_type":"code","colab":{}},"source":["# Obtain powers of alpha and theta band\n","\n","# Correct trials for stimulus on one side\n","incorrect_one_side = np.logical_and(one_side_stim,incorrect)\n","correct_trials    = np.where(correct_one_side == True)[0]\n","incorrect_trials  = np.where(incorrect_one_side == True)[0]\n","\n","\n","def get_powers(area1='VISam',area2='LGd', dat_LFP= dat_LFP,dat = dat,correct_trials = correct_trials, incorrect_trials = incorrect_trials):\n","  \"\"\"\n","  This function takes the areas into account and computes the band powers by obtaining the \n","  power values at every time bin (in a particular frequency band) and then takes the \n","  average of those power values for each trial\n","\n","  input arguments:\n","  area1 : Brain area 1\n","  area2 : Brain area 2\n","  dat_LFP: LFP data\n","  dat: dictionary containing response times, time vectors\n","  correct_trials: correct trials for one sided stimulus\n","  incorrect_trials: incorrect trials for one sided stimulus\n","\n","  output arguments:\n","  correct_trials_alpha_power_signal1/2 : Alpha power for correct trials for signal 1/ 2\n","  incorrect_trials_alpha_power_signal1/2 : Alpha power for incorrect trials for signal 1/2\n","  correct_trials_theta_power_signal1/2: Theta power for correct trials for signal 1/2\n","  incorrect_trials_theta_power_signal1/2: Theta power for incorrect trials for signal 1/2 \n","\n","  \"\"\"\n","  # Initializing empty arrays to append\n","  correct_trials_alpha_power_signal1 = np.array([]) ; correct_trials_alpha_power_signal2 = np.array([]);\n","  correct_trials_theta_power_signal1 = np.array([]) ; correct_trials_theta_power_signal2 = np.array([]);\n","  incorrect_trials_alpha_power_signal1 = np.array([]); incorrect_trials_alpha_power_signal2 = np.array([])\n","  incorrect_trials_theta_power_signal1 = np.array([]); incorrect_trials_theta_power_signal2 = np.array([])\n","\n","  ind1 = dat_LFP[\"brain_area_lfp\"].index(area1)\n","  ind2 = dat_LFP[\"brain_area_lfp\"].index(area2)\n","  regions = np.array(dat_LFP[\"brain_area_lfp\"]) # this is for multiple occurences of one region\n","\n","  # If more than one instance, taking the first recording area into account\n","  if dat_LFP[\"brain_area_lfp\"].count(area1) >1:\n","       ind1 = np.where(regions == area1)[0][1]\n","\n","  if dat_LFP[\"brain_area_lfp\"].count(area2) >1:\n","      ind2 = np.where(regions == area2)[0][1]\n","  \n","  for i_trial in range(len(dat['response'])):\n","    # Compute Fourier transform \n","    freq_vals, fft_signal1, fft_signal2 = fourier(NT = NT, dt = 10, signal1 = dat_LFP[\"lfp\"][ind1,i_trial,:] , signal2 = dat_LFP[\"lfp\"][ind2,i_trial,:],\n","                                                  dat = dat_LFP,trial_num = i_trial, area1 = area1, area2 = area2, fig_size = (18,10))\n","    # fft_signal1 = 10 * np.log10(fft_signal1) # In dB, can use to visualize power spectrum but powers are calculated using raw power \n","    # fft_signal2 = 10 * np.log10(fft_signal2)\n","    alpha_indices = np.where(np.logical_and(freq_vals>=8, freq_vals<=12)) # alpha - 8-12 Hz # get indices where frequency values are in alpha and theta range\n","    theta_indices = np.where(np.logical_and(freq_vals>=4, freq_vals<=7)) # theta - 4-7 Hz\n","\n","    if i_trial in correct_trials:\n","      correct_trials_alpha_power_signal1 =  np.append(correct_trials_alpha_power_signal1, np.mean(fft_signal1[alpha_indices]))\n","      correct_trials_alpha_power_signal2 = np.append(correct_trials_alpha_power_signal2, np.mean(fft_signal2[alpha_indices]))\n","\n","      correct_trials_theta_power_signal1 = np.append(correct_trials_theta_power_signal1, np.mean(fft_signal1[theta_indices]))\n","      correct_trials_theta_power_signal2 = np.append(correct_trials_theta_power_signal2, np.mean(fft_signal2[theta_indices]))\n","   \n","    elif i_trial in incorrect_trials:\n","      incorrect_trials_alpha_power_signal1 = np.append(incorrect_trials_alpha_power_signal1, np.mean(fft_signal1[alpha_indices])) \n","      incorrect_trials_alpha_power_signal2 = np.append(incorrect_trials_alpha_power_signal2, np.mean(fft_signal2[alpha_indices]))\n","\n","      incorrect_trials_theta_power_signal1 = np.append(incorrect_trials_theta_power_signal1, np.mean(fft_signal1[theta_indices]))\n","      incorrect_trials_theta_power_signal2 = np.append(incorrect_trials_theta_power_signal2, np.mean(fft_signal2[theta_indices]))\n","  \n","  return correct_trials_alpha_power_signal1, correct_trials_alpha_power_signal2,correct_trials_theta_power_signal1,correct_trials_theta_power_signal2,\\\n","  incorrect_trials_alpha_power_signal1,incorrect_trials_alpha_power_signal2, incorrect_trials_theta_power_signal1, incorrect_trials_theta_power_signal2\n","\n","\n","# Function ends\n","\n","\n","# correct_trials_alpha_power_signal1, correct_trials_alpha_power_signal2,correct_trials_theta_power_signal1,correct_trials_theta_power_signal2,incorrect_trials_alpha_power_signal1,incorrect_trials_alpha_power_signal2, incorrect_trials_theta_power_signal1, incorrect_trials_theta_power_sign = get_powers()\n","correct_trials_alpha_power_signal1, correct_trials_alpha_power_signal2,correct_trials_theta_power_signal1,correct_trials_theta_power_signal2,\\\n","incorrect_trials_alpha_power_signal1,incorrect_trials_alpha_power_signal2, incorrect_trials_theta_power_signal1, \\\n","incorrect_trials_theta_power_signal2 = get_powers(area1='VISam',area2='LGd', dat_LFP= dat_LFP,dat = dat,correct_trials = correct_trials,\n","                                                  incorrect_trials = incorrect_trials)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HXYxXKJKFj1C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1596040615541,"user_tz":-330,"elapsed":798,"user":{"displayName":"Keerthana Manikandan","photoUrl":"https://lh6.googleusercontent.com/-QQCmEevJOBM/AAAAAAAAAAI/AAAAAAAAAMI/-iZbsmOHbZk/s64/photo.jpg","userId":"01482527171893239923"}},"outputId":"6f698ef9-7d58-4c44-cb42-8576b94f9cce"},"source":["# plt.scatter(correct_trials_alpha_power_signal1,correct_trials_theta_power_signal1)\n","# plt.show()\n","# from scipy import stats\n","# corr, pVal = stats.pearsonr(incorrect_trials_alpha_power_signal1,incorrect_trials_theta_power_signal1)\n","# print(corr,pVal)\n","# print(dat[\"response\"][incorrect_trials], dat[\"response\"][correct_trials])\n","par1 = correct_trials_theta_power_signal1 - correct_trials_alpha_power_signal1 ** -1\n","par2 = correct_trials_theta_power_signal1 ** 2\n","\n","corr,pVal = stats.pointbiserialr(par, dat[\"response\"][correct_trials])\n","print(corr,pVal)\n","# So the square of theta powers for VISam are correlated with the correct response?\n","\n","# Creating a dictionary to store parameters\n","trial_params = {\n","    \"responses\": dat[\"response\"][correct_trials]\n","    \"correct_trials_theta_power_signal1\": correct_trials_theta_power_signal1\n","    \"correct_trials_alpha_power_signal1\": correct_trials_alpha_power_signal1\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.22618671768425094 0.018580557499265016\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0HQ_qHhYEDg1","colab_type":"code","colab":{}},"source":["# Bayesian regressor - to try with regularizer\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn import linear_model\n","import numpy as np\n","X = np.vstack([correct_trials_alpha_power_signal1,correct_trials_theta_power_signal1])\n","y = dat[\"response\"][correct_trials]\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","reg = linear_model.BayesianRidge()\n","reg.fit(X.T,y)#(X.reshape(-1, 1), y)\n","a =X.T\n","print(reg.predict(a[8:10,:])) # Testing with random samples\n","print( y[8:10]) # actual response"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5C-3nAdcrcC","colab_type":"code","colab":{}},"source":["# THE DECODER.......................................................\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","\n","sampl_rate = 1/(dt/1000) # sampling rate\n","nyquist = sampl_rate/2\n","hz = np.linspace(0,sampl_rate, NT) # frequency vector same for all\n","\n","alpha_indices = np.where(np.logical_and(hz>=8, hz<=12)) # alpha - 8-12 Hz # get indices where frequency values are in alpha and theta range\n","theta_indices = np.where(np.logical_and(hz>=4, hz<=7)) \n","\n","incorrect_one_side = np.logical_and(one_side_stim,incorrect)\n","correct_trials    = np.where(correct_one_side == True)[0]\n","incorrect_trials  = np.where(incorrect_one_side == True)[0]\n","\n","for i_area in range(12):\n","  alpha_power = np.array([]); theta_power = np.array([])\n","  \n","  for i_trial in range(len(dat['response'])):\n","    freq_seri1 = fftpack.fft(dat_LFP['lfp'][i_area][i_trial]) #compute freq series\n","    amp1 = 2.0/NT * np.abs(freq_seri1)  # amplitude vector,\n","    return_ind = int(np.where(abs(hz-nyquist) == np.min(abs(hz - nyquist)))[0][0])+1\n","    amp1 = amp1[:return_ind]\n","    if i_trial in correct_trials:\n","      alpha_power = np.append(alpha_power, np.mean(amp1[alpha_indices]))\n","      theta_power = np.append(theta_power, np.mean(amp1[theta_indices]))\n","\n","  X = np.vstack([alpha_power,theta_power])  # Naive Bayesian decoder\n","  y = dat[\"response\"][correct_trials]\n","  X_train, X_test, y_train, y_test = train_test_split(X.T, y, test_size=0.5)\n","  gnb = GaussianNB()\n","  y_pred = gnb.fit(X_train, y_train).predict(X_test)\n","  print(dat_LFP['brain_area_lfp'][i_area],':',accuracy_score(y_test,y_pred)* 100)\n"],"execution_count":null,"outputs":[]}]}